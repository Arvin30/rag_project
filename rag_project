# embedding.py
from sentence_transformers import SentenceTransformer

class EmbeddingModel:
    def __init__(self, model_name="BAAI/bge-small-zh-v1.5"):
        self.model = SentenceTransformer(model_name)
    
    def encode(self, texts):
        if isinstance(texts, str):
            texts = [texts]
        return self.model.encode(texts, normalize_embeddings=True)


# rag.py
from embedding import EmbeddingModel

embedder = EmbeddingModel("BAAI/bge-small-zh-v1.5")
query_vec = embedder.encode("你的问题？")  # shape: (768,)


# vector_store.py
import chromadb
from chromadb.utils import embedding_functions

class ChromaVectorStore:
    def __init__(self, persist_dir="./chroma_db", collection_name="rag_docs"):
        self.client = chromadb.PersistentClient(path=persist_dir)
        # 使用自定义 embedding 函数（或传入 None，由外部处理）
        self.collection = self.client.get_or_create_collection(
            name=collection_name,
            metadata={"hnsw:space": "cosine"}  # 相似度度量
        )
    
    def add_documents(self, ids, texts, embeddings=None):
        # 如果未提供 embeddings，可在此调用 embedder
        self.collection.add(
            ids=ids,
            documents=texts,
            embeddings=embeddings  # 可为 None，但建议提前计算好
        )
    
    def search(self, query_embedding, top_k=3):
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k
        )
        return results['documents'][0], results['distances'][0]



# main.py
from embedding import EmbeddingModel
from vector_store import ChromaVectorStore

# 初始化
embedder = EmbeddingModel()
vector_db = ChromaVectorStore()

# 假设你有一批文档
docs = ["RAG 是检索增强生成...", "向量数据库用于存储语义向量..."]
doc_ids = [f"doc_{i}" for i in range(len(docs))]

# 计算嵌入并存入
embeddings = embedder.encode(docs)
vector_db.add_documents(doc_ids, docs, embeddings)

# 查询
query = "什么是 RAG？"
q_emb = embedder.encode(query)
retrieved_docs, scores = vector_db.search(q_emb)

print("检索到的上下文：", retrieved_docs)
